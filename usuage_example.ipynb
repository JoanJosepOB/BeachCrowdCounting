{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Usuage example for the beach pedestrian detector\n",
    "\n",
    "Authors:\n",
    "- Guillem Bibiloni Femenias\n",
    "- Joan Josep Ordóñez Bonet\n",
    "\n",
    "In this file it is shown an example of how the detector can be used. Initially, the data has to be loaded using the function ```load_data``` from the module, indicating the folder from where the images come from. This folder must contain also the labeling of the images. After this load, the proper execution of the detector can be run for each image using the ```analyze_image``` function, returning both an image with the regions considered as pedestrians and the centroid of each region, where the person is supposed to be at.\n",
    "\n",
    "After this analysis, a proper evaluation can be performed, both for the entire dataset and for each image. The evaluation on the whole dataset is performed by analysing the _MSE_ metric on the count of detections with the ```evaluate_mse``` function. The evaluation on each image is performed by using the accuracy of the centroids detected with the ```evaluate_accuracy``` function. This evaluation is parametrized with a threshold, which is used as the maximum euclidean distance to which a detection is considered valid."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bcee444fe1ea018"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import image_analyzer\n",
    "import cv2\n",
    "\n",
    "color_images, gt_positions, gt_count = image_analyzer.load_data(\"images\")\n",
    "\n",
    "results = []\n",
    "centroids = []\n",
    "\n",
    "for image in color_images:\n",
    "    resulting_img, detections = image_analyzer.analyze_image(image)\n",
    "    results.append(resulting_img)\n",
    "    centroids.append(detections)\n",
    "    \n",
    "for image, name, cents in zip(results, gt_count[\"Image\"], centroids):\n",
    "    cv2.imwrite(\"results/{}\".format(name), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    for c in cents:\n",
    "        cv2.circle(image, c, 5, (0,255,0), -1)\n",
    "\n",
    "    cv2.imwrite(\"results_centroids/{}\".format(name), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "detector_mse = image_analyzer.evaluate_mse(gt_count[\"NPeople\"], [len(x) for x in centroids])\n",
    "\n",
    "threshold = 15\n",
    "scores = []\n",
    "\n",
    "for idx, image in enumerate(gt_count[\"Image\"].tolist()):\n",
    "    predict_ = centroids[idx]\n",
    "    gt_ = gt_positions[gt_positions[\"Image\"] == image][[\"X\", \"Y\"]].values.tolist()\n",
    "\n",
    "    scores.append(image_analyzer.evaluate_accuracy(gt_, predict_, threshold))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T12:25:50.114499200Z",
     "start_time": "2023-12-03T12:25:44.702747100Z"
    }
   },
   "id": "aaf4cf9542b37e23"
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this dataset, the results are as follows:\n",
    "\n",
    "- Overall MSE metric:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d25f7966314aefe4"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "2280.4"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_mse"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T12:25:50.130340500Z",
     "start_time": "2023-12-03T12:25:50.117504200Z"
    }
   },
   "id": "4de91e13ea19871e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Accuracies:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77f281bbd4efaf30"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[0,\n 0,\n 0.34285714285714286,\n 0.38461538461538464,\n 0.5081967213114754,\n 0.524390243902439,\n 0.5411764705882353,\n 0.40425531914893614,\n 0.46,\n 0.3894736842105263]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-03T12:25:50.177589700Z",
     "start_time": "2023-12-03T12:25:50.131343400Z"
    }
   },
   "id": "878bce5a545f3de"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
